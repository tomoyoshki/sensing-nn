{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_preprocess(time_loc_inputs):\n",
    "    \"\"\"Run FFT on the time-domain input.\n",
    "    time_loc_inputs: [b, c, i, s]\n",
    "    freq_loc_inputs: [b, c, i, s]\n",
    "    \"\"\"\n",
    "    freq_loc_inputs = dict()\n",
    "\n",
    "    for loc in time_loc_inputs:\n",
    "        freq_loc_inputs[loc] = dict()\n",
    "        for mod in time_loc_inputs[loc]:\n",
    "            loc_mod_freq_output = torch.fft.fft(time_loc_inputs[loc][mod], dim=-1)\n",
    "            loc_mod_freq_output = torch.view_as_real(loc_mod_freq_output)\n",
    "            loc_mod_freq_output = loc_mod_freq_output.permute(0, 1, 4, 2, 3)\n",
    "            b, c1, c2, i, s = loc_mod_freq_output.shape\n",
    "            loc_mod_freq_output = loc_mod_freq_output.reshape(b, c1 * c2, i, s)\n",
    "            freq_loc_inputs[loc][mod] = loc_mod_freq_output\n",
    "\n",
    "    return freq_loc_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_index(data_index):\n",
    "    stage = ['train', 'val', 'test']\n",
    "    index_files = []\n",
    "    for s in stage:\n",
    "        data_index_path = data_index + f\"{s}_index.txt\"\n",
    "        index_file = np.loadtxt(data_index_path, dtype=str)    \n",
    "        index_files.append(index_file)\n",
    "\n",
    "    index_files = np.concatenate(index_files)\n",
    "    index_files = list(set(list(index_files)))\n",
    "    return index_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psd(data_fft):\n",
    "    energy_spectrum = dict()\n",
    "    for loc in data_fft:\n",
    "        energy_spectrum[loc] = dict()\n",
    "        for mod in data_fft[loc]:\n",
    "            energy_spectrum[loc][mod] = torch.abs(data_fft[loc][mod]) ** 2\n",
    "    return energy_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_spectrum(samples):\n",
    "    # scale energy spectrum for energy distribution\n",
    "    min_psd = {}\n",
    "    max_psd = {}\n",
    "    for sample in samples.values():\n",
    "        for loc in sample['psd']:\n",
    "            if loc not in min_psd:\n",
    "                min_psd[loc] = dict()\n",
    "                max_psd[loc] = dict()\n",
    "            for mod in sample['psd'][loc]:\n",
    "                if mod not in min_psd[loc]:\n",
    "                    min_psd[loc][mod] = sample['psd'][loc][mod]\n",
    "                    max_psd[loc][mod] = sample['psd'][loc][mod]\n",
    "                else:\n",
    "                    min_psd[loc][mod] = torch.minimum(min_psd[loc][mod], sample['psd'][loc][mod])\n",
    "                    max_psd[loc][mod] = torch.maximum(max_psd[loc][mod], sample['psd'][loc][mod])\n",
    "    \n",
    "    for sample in samples.values():\n",
    "        sample['energy_spectrum'] = {}\n",
    "        for loc in sample['psd']:\n",
    "            if loc not in sample['energy_spectrum']:\n",
    "                sample['energy_spectrum'][loc] = {}\n",
    "            for mod in sample['psd'][loc]:\n",
    "                sample['energy_spectrum'][loc][mod] = (sample['psd'][loc][mod] - min_psd[loc][mod]) / (max_psd[loc][mod] - min_psd[loc][mod] + 1e-8)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence(samples):\n",
    "    # Compute average coherence for coherence distribution\n",
    "    for sample_id, sample in samples.items():\n",
    "        sample['coherence'] = {}\n",
    "        for loc in sample['fft']:\n",
    "            sample['coherence'][loc] = {}\n",
    "            for mod in sample['fft'][loc]:\n",
    "                \n",
    "                # initialize coherence sum for sample i\n",
    "                coherence_sum = np.zeros_like(sample['fft'][loc][mod], dtype=np.float64)\n",
    "                count = 0\n",
    "                for other_id, other_sample in samples.items():\n",
    "                    if sample_id == other_id:\n",
    "                        continue # D - 1\n",
    "                        \n",
    "                    # compute cross-PSD\n",
    "                    cross_psd = sample['fft'][loc][mod] * torch.conj(other_sample['fft'][loc][mod])\n",
    "                    psd_product = np.multiply(np.abs(sample['fft'][loc][mod]) ** 2, np.abs(other_sample['fft'][loc][mod]) ** 2) + 1e-8\n",
    "                    \n",
    "                    # compute cross coherence and add to coherence sum\n",
    "                    coherence_sum = np.add(coherence_sum, (np.abs(cross_psd) ** 2 / psd_product).real)\n",
    "                    count += 1\n",
    "                \n",
    "                # sample i average coherence\n",
    "                sample['coherence'][loc][mod] = coherence_sum / count if count > 0 else coherence_sum\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_shape(data):\n",
    "    for loc in data:\n",
    "        for mod in data[loc]:\n",
    "            print(f\"{loc} {mod} {data[loc][mod].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_energy_coherence_for_dataset(data_index):\n",
    "    index_files = load_data_index(data_index)\n",
    "    samples = {}\n",
    "    \n",
    "    \n",
    "    print(f\"Compute PSD for {len(index_files)} samples\")\n",
    "    # compute Power Spectrum Density (PSD)\n",
    "    for pt_path in index_files:\n",
    "        if pt_path not in samples:\n",
    "            samples[pt_path] = {}\n",
    "        \n",
    "        sample = torch.load(pt_path, weights_only=False)\n",
    "        data = sample['data']\n",
    "        for loc in data:\n",
    "            for mod in data[loc]:\n",
    "                data[loc][mod] = data[loc][mod].unsqueeze(0)\n",
    "        \n",
    "        # print_data_shape(data)\n",
    "        data_fft = fft_preprocess(data)\n",
    "        \n",
    "        psd = compute_psd(data_fft)\n",
    "        samples[pt_path]['psd'] = psd\n",
    "        samples[pt_path]['fft'] = data_fft        \n",
    "    \n",
    "    print(f\"Compute energy spectrum for {len(samples)} samples\")\n",
    "    samples = compute_energy_spectrum(samples)\n",
    "    \n",
    "    print(f\"Compute coherence for {len(samples)} samples\")\n",
    "    samples = compute_coherence(samples)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(samples):\n",
    "    print(f\"Save samples for {len(samples)} samples\")\n",
    "    for sample_pt in samples:\n",
    "        print(samples[sample_pt].keys())\n",
    "        \n",
    "        original_sample = torch.load(sample_pt, weights_only=False)\n",
    "        original_sample['energy_spectrum'] = samples[sample_pt]['energy_spectrum']\n",
    "        original_sample['coherence'] = samples[sample_pt]['coherence']\n",
    "        torch.save(original_sample, sample_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute energy spectrum for 23821 samples\n",
      "Compute coherence for 23821 samples\n"
     ]
    }
   ],
   "source": [
    "samples = set_energy_coherence_for_dataset(\"/home/tkimura4/data/datasets/ACIDS/random_partition_index_vehicle_classification/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_samples(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
