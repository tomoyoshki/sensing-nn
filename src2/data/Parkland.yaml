# data paths  
pretrain_index_file: /home/tkimura4/data/datasets/MOD/Parkland/time_data_partition/pretrain_index.txt 
vehicle_classification:
        num_classes: 7  # number of classes
        class_names: ["Polaris", "Warhog", "Truck", "motor", "tesla", "mustang", "walk"]
        train_index_file: /home/tkimura4/data/datasets/MOD/Parkland/time_data_partition/train_index.txt 
        val_index_file: /home/tkimura4/data/datasets/MOD/Parkland/time_data_partition/val_index.txt  
        test_index_file: /home/tkimura4/data/datasets/MOD/Parkland/time_data_partition/test_index.txt 

repetition: 3


# Segments
num_segments: 10

# Locations 
num_locaiton: 1
location_names: ["shake"]

# Modality names
num_sensors: 2
modality_names: ["seismic", "audio"]

# Location modalities
loc_modalities: 
        shake: ["seismic", "audio"]
loc_mod_in_freq_channels:
        shake:
                audio: 2
                seismic: 2
                acc: 6
loc_mod_in_time_channels:
        shake:
                audio: 1
                seismic: 1
                acc: 3
loc_mod_spectrum_len:
        shake:
                audio: 1600
                seismic: 20
                acc: 20

# For sequence-based contrastive learning 
seq_len: 4

quantization:
        bn_type: "float" # switch, float, transitional are valid options
        enable: True # False will run everything in float
        bitwidth_options: [8,16,32]
        joint_quantization_batch_size: 1
        # joint_quantization: False
        training_type: "joint_quantization" # joint_quantization, vanilla
        activation_quantization: "pact"
        weight_quantization: "dorefa"
        switchable_clipping: True
        sat_weight_normalization: False
        test_and_val_average_bitwidths : [8,16,32]
        test_and_val_total_schemes : 4
        delta : 1
        teacher_student: False
        teacher_bn_type: "float" # other option is switchable
        teacher_selection_strategy: "activation_min" # other options weight_min, activation_max, weight_max, activation_min
        kurtosis_regularization: False
        kurtosis_target: 1.8    
        kurtosis_weight: 0.1
        coherence_weight: 0.3
        energy_weight: 0.5
        loss_function_for_activation: ["ce_output_activation"] # other options that can be added to list kl_divergence_st_output_activaation, kl_all_hidden_activations
        tile_mode: False
        scale_importance_vector: False
        number_of_tiles: 4
        importance_vector_scaling_function: "none" # energy, none
        testing_type: "model_self_selection_per_test" # model_self_selection_per_test, mean_mixed_precision
        enable_grad_scaling: True
        grad_scaling_function: "energy"
        # training_type: "vanilla"
                
ResNet:
        # Architecture settings
        block_type: "basic"  # "basic" for ResNet18/34, "bottleneck" for ResNet50+
        layers: [2, 2, 2, 2]  # ResNet18
        # layers: [3, 4, 6, 3]  # ResNet34
        # layers: [3, 4, 6, 3]  # ResNet50 (with block_type: "bottleneck")
        dropout_ratio: 0.2
        fc_dim: 256

  # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.05

  # LR scheduler
        lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 50
                start_epoch: 0
                decay_epochs: 2
                decay_rate: 0.2

        fixed_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["no"]

# DeepSense config
DeepSense:
        dropout_ratio: 0.2 
        # single interval + location + modality
        loc_mod_in_conv_stride:
                audio: [1, 80]
                seismic: [1, 1]
        loc_mod_conv_lens: 
                audio: [[1, 80], [1, 5], [1, 5]]
                seismic: [[1, 3], [1, 3], [1, 3]]
        loc_mod_out_channels: 128
        loc_mod_conv_inter_layers: 4
        # single interval + location
        loc_conv_lens: [[1, 4], [1, 4], [1, 4]]
        loc_out_channels: 128
        loc_conv_inter_layers: 3
        # recurrent layer
        recurrent_dim: 256
        recurrent_layers: 2
        # FC layer
        fc_dim: 512
        pretrained_head: "linear"
        # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        # LR scheduler
        lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 300
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["phase_shift"]
        fixed_augmenters:
                time_augmenters: ["mixup"]
                freq_augmenters: ["no"]

TransformerV4:
        dropout_ratio: 0.2
        drop_path_rate: 0.1
        attn_drop_rate: 0.2
        # loc mod freq feature
        in_stride:
                audio: 1
                seismic: 1
        # single modality
        time_freq_out_channels: 64
        time_freq_head_num: 4
        time_freq_block_num: 
                audio: [2, 2, 4]
                seismic: [2, 2, 4]
        # modality fusion
        mod_out_channels: 256
        mod_head_num: 4
        mod_block_num: 2
        # location fusion
        loc_out_channels: 256 # loc_out_channels == mod_out_channels
        loc_head_num: 4
        loc_block_num: 2
        # SwinTransformer configs
        window_size: 
                audio: [3, 3] 
                seismic: [3, 3] 
        mlp_ratio: 4.
        qkv_bias: True
        APE: False
        patch_norm: True
        patch_size:
                freq:
                        audio: [1, 40]
                        seismic: [1, 1]
        # FC layer
        fc_dim: 512
        pretrained_head: "linear"
        # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        # LR scheduler
        lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 100
                decay_rate: 0.2
        # Data Augmenters:
        random_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["no"]
        fixed_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["phase_shift"]

# ------------------------------------------- Data Augmenter Configs ------------------------------------------
# Mixup config
mixup:
        mixup_alpha: 1.0
        cutmix_alpha: 1.0
        cutmix_minmax: null
        prob: 1.0
        switch_prob: 0.75
        mode: 'random_batch'
        label_smoothing: 0
        num_classes: 7

jitter:
        std_in_percent: 0.2
        prob: 0.5

rotation:
        angles: [90, 180, 270]

permutation:
        prob: 0.5

scaling:
        prob: 0.5
        std: 0.2

time_warp:
        prob: 0.5
        magnitude: 0.2
        order: 6

mag_warp:
        prob: 0.5
        magnitude: 0.05
        order: 4

negation:
        prob: 0.5

channel_shuffle:
        prob: 0.5

freq_mask:
        prob: 0.5 
        mask_ratio: 0.3

time_mask:
        prob: 0.5
        mask_ratio: 0.3

phase_shift:
        prob: 0.5 

horizontal_flip:
        prob: 0.5
