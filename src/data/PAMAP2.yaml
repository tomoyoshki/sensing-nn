# data paths  
pretrain_index_file: /home/sl29/data/PAMAP2/time_data_partition/train_index.txt 
activity_classification:
        num_classes: 18  # number of classes
        class_names: ["lying", "sitting", "standing", "walking", "running", "cycling", "nordic walking", "watching TV", "computer work", "car driving", "ascending stairs", "descending stairs", "vacuum cleaning", "ironing", "folding laundry", "house cleaning", "playing soccer", "rope jumping"]
        train_index_file: /home/sl29/data/PAMAP2/time_data_partition/train_index.txt 
        val_index_file: /home/sl29/data/PAMAP2/time_data_partition/test_index.txt  
        test_index_file: /home/sl29/data/PAMAP2/time_data_partition/test_index.txt 

repetition: 3


# Segments
num_segments: 9

# Locations 
num_locaiton: 1
location_names: ["hand"]

# Modality names
num_sensors: 3
modality_names: ["Acc", "Gyro", "Mag"]

# Location modalities
loc_mod_in_freq_channels:
        hand:
                Acc: 6
                Gyro: 6
                Mag: 6
loc_mod_in_time_channels:
        hand:
                Acc: 3
                Gyro: 3
                Mag: 3
loc_mod_spectrum_len:
        hand:
                Acc: 40
                Gyro: 40
                Mag: 40

# For sequence-based contrastive learning 
seq_len: 4

# DeepSense config
DeepSense:
        dropout_ratio: 0.2 
        # single interval + location + modality
        loc_mod_in_conv_stride:
                Acc: [1, 1]
                Gyro: [1, 1]
                Mag: [1, 1]
        loc_mod_conv_lens: 
                Acc: [[1, 5], [1, 5], [1, 5]]
                Gyro: [[1, 5], [1, 5], [1, 5]]
                Mag: [[1, 5], [1, 5], [1, 5]]
        loc_mod_out_channels: 64
        loc_mod_conv_inter_layers: 2
        # single interval + location
        loc_conv_lens: [[1, 4], [1, 4], [1, 4]]
        loc_out_channels: 64
        loc_conv_inter_layers: 2
        # recurrent layer
        recurrent_dim: 64
        recurrent_layers: 2
        # FC layer
        fc_dim: 128
        pretrained_head: "linear"
        # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        # LR scheduler
        lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 100
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["phase_shift"]
        fixed_augmenters:
                time_augmenters: ["mixup"]
                freq_augmenters: ["no"]
        
TransformerV4:
        dropout_ratio: 0.2
        drop_path_rate: 0.1
        attn_drop_rate: 0.2
        # loc mod freq feature
        in_stride:
                Acc: 1
                Gyro: 1
                Mag: 1
        # single modality
        time_freq_out_channels: 32
        time_freq_head_num: 4
        time_freq_block_num: 
                Acc: [2, 2, 2]
                Gyro: [2, 2, 2]
                Mag: [2, 2, 2]
        # modality fusion
        mod_out_channels: 128
        mod_head_num: 4
        mod_block_num: 2
        # location fusion
        loc_out_channels: 128 # loc_out_channels == mod_out_channels
        loc_head_num: 4
        loc_block_num: 2
        # SwinTransformer configs
        window_size: 
                Acc: [3, 5] 
                Gyro: [3, 5] 
                Mag: [3, 5]
        mlp_ratio: 2.
        qkv_bias: True
        APE: False
        patch_norm: True
        patch_size:
                freq:
                        Acc: [1, 2] 
                        Gyro: [1, 2] 
                        Mag: [1, 2]
        # FC layer
        fc_dim: 128
        pretrained_head: "linear"
        # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        # LR scheduler
        lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 100
                decay_rate: 0.2
        # Data Augmenters:
        random_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["no"]
        fixed_augmenters:
                time_augmenters: ["mixup"]
                freq_augmenters: ["phase_shift"]

TSMixer:
        dim: 32
        norm_eps: 0.01
        patch_length: 
                Acc: 8
                Gyro: 8
                Mag: 8
        patch_stride:
                Acc: 4
                Gyro: 4
                Mag: 4
        use_positional_encoding: True
        positional_encoding_type: "sincos"
        num_layers: 3
        self_attn: True
        gated_attn: True
        expansion_factor: 4
        dropout: 0.2
        self_attn_heads: 2
        scaling_dim: 2
        minimum_scale: 0.000001
        default_scale: 1
        keepdim: True
        scaling: "no"
        post_init: True
        mode: "common_channel" # mix_channel or common_channel
        norm_mlp: "batch" # anything does not include batch

        head_aggregation: None
        output_range: None
        head_dropout: 0.2
        
        fc_dim: 512
        
        # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        # LR scheduler
        lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 300
                decay_rate: 0.2

        fixed_augmenters:
                time_augmenters: ["mixup"]
                freq_augmenters: ["phase_shift"]

MLPMixer:
        dim: 128
        patch_size:
                freq:
                        Acc: [1, 2] 
                        Gyro: [1, 2] 
                        Mag: [1, 2]
        in_stride:
                Acc: 1
                Gyro: 1
                Mag: 1
        
        depth: 8
        time_freq_out_channels: 64
        token_dim: 256
        channel_dim: 1024
        dim: 512
        fc_dim: 512
        # Optimizer config
        optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        # LR scheduler
        lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 300
                decay_rate: 0.2

        fixed_augmenters:
                time_augmenters: ["mixup"]
                freq_augmenters: ["phase_shift"]

SimCLR:
        emb_dim: 128
        temperature: 0.07
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.0001
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

MoCo:
        emb_dim: 128
        temperature: 0.07
        momentum: 0.99
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.00001
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

CMC:
        emb_dim: 128
        nce_k: 16384
        nce_t: 0.07
        nce_momentum: 0.5
        softmax: True
        temperature: 0.07
        input_size: 256
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0005
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.005
                decay_rate: 0.00001
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

CMCV2:
        emb_dim: 128
        temperature: 0.5
        ranking_margin: 0.0
        inter_rank_margin: 1
        intra_rank_margin: 0.05
        shared_contrastive_loss_weight: 1
        private_contrastive_loss_weight: 1
        orthogonal_loss_weight: 3
        rank_loss_weight: 5
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0005
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: # 0.05 for Transformer, 0.5 for DeepSense
                        TransformerV4: 0.05
                        DeepSense: 0.5
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.005
                decay_rate: 0.2
        finetune_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

TNC: 
        emb_dim: 256
        temperature: 0.07
        weight: 0.05
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 2000
                start_epoch: 0
                decay_epochs: 500
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.005
                decay_rate: 0.2
        finetune_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

TS2Vec:
        emb_dim: 512
        temperature: 0.07
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 2000
                start_epoch: 0
                decay_epochs: 500
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.005
                decay_rate: 0.2
        finetune_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # data augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "scaling", "channel_shuffle"]
                freq_augmenters: ["phase_shift"]

TSTCC:
        emb_dim: 512
        temperature: 0.07
        lambda1: 1
        lambda2: 0.7
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 2000
                start_epoch: 0
                decay_epochs: 500
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.005
                decay_rate: 0.2
        finetune_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # data augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "scaling", "channel_shuffle"]
                freq_augmenters: ["phase_shift"]

Cosmo:
        temperature: 1
        num_positive: 10
        emb_dim: 128
        contrast_mode: all
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.00001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.00001
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # data augmenters
        random_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: []

Cocoa:
        temperature: 0.5
        scale_loss: 0.03125
        lambd: 3.9e-3
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.005
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # data augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

MTSS:
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "AdamW"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.005
        finetune_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 500
                start_epoch: 0
                decay_epochs: 150
                decay_rate: 0.2
        # data augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling"]
                freq_augmenters: ["phase_shift"]

GMC:
        emb_dim: 256
        temperature: 0.2
        # Pre training  
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 2000
                start_epoch: 0
                decay_epochs: 500
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.0003
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.0001
                decay_rate: 0.2
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # data augmenters
        random_augmenters:
                time_augmenters: ["permutation", "negation", "time_warp", "horizontal_flip", "mag_warp", "scaling", "channel_shuffle"]
                freq_augmenters: ["phase_shift"]

MAE:
        masked_ratio:
                Acc: 0.75
                Gyro: 0.75
                Mag: 0.75
        patch_size:
                Acc: [1, 1]
                Gyro: [1, 1]
                Mag: [1, 1]
        pretrain_optimizer:
                name: "AdamW"
                start_lr: 0.0001
                warmup_lr: 0.000001
                min_lr: 0.0000001
                clip_grad: 5.0
                weight_decay: 0.05
        pretrain_lr_scheduler:
                name: "cosine"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 1000
                start_epoch: 0
                decay_epochs: 200
                decay_rate: 0.2
        # Fine tuning 
        finetune_optimizer:
                name: "Adam"
                start_lr: 0.001
                warmup_lr: 0.000001
                min_lr: 0.000001
                clip_grad: 5.0
                weight_decay: 0.0005
        finetune_lr_scheduler:
                name: "step"
                warmup_prefix: True
                warmup_epochs: 0
                train_epochs: 200
                start_epoch: 0
                decay_epochs: 50
                decay_rate: 0.2
        # Augmenters
        random_augmenters:
                time_augmenters: ["no"]
                freq_augmenters: ["no"]

# ------------------------------------------- Data Augmenter Configs ------------------------------------------
# Mixup config
mixup:
        mixup_alpha: 1.0
        cutmix_alpha: 1.0
        cutmix_minmax: null
        prob: 1.0
        switch_prob: 0.75
        mode: 'random_batch'
        label_smoothing: 0
        num_classes: 7

jitter:
        std_in_percent: 0.2
        prob: 0.5

rotation:
        angles: [90, 180, 270]

permutation:
        prob: 0.5

scaling:
        prob: 0.5
        std: 0.2

time_warp:
        prob: 0.5
        magnitude: 0.2
        order: 6

mag_warp:
        prob: 0.5
        magnitude: 0.05
        order: 4

negation:
        prob: 0.5

channel_shuffle:
        prob: 0.5

freq_mask:
        prob: 0.5 
        mask_ratio: 0.3

time_mask:
        prob: 0.5
        mask_ratio: 0.3

phase_shift:
        prob: 0.5 

horizontal_flip:
        prob: 0.5
